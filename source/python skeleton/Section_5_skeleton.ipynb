{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "class color:\n",
    "    PURPLE = '\\033[95m'\n",
    "    CYAN = '\\033[96m'\n",
    "    DARKCYAN = '\\033[36m'\n",
    "    BLUE = '\\033[94m'\n",
    "    GREEN = '\\033[92m'\n",
    "    YELLOW = '\\033[93m'\n",
    "    RED = '\\033[91m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "    END = '\\033[0m'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the mean absolute error:\n",
    "$$\n",
    "MAE = \\frac{1}{N}\\sum_{i=1}^N |y_i-x_i^\\top\\theta|\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def get_MAE(theta, X, y):\n",
    "    ypred = X@theta.T\n",
    "    mae = np.average(np.abs(ypred - y), axis=0)\n",
    "    \n",
    "    # compare to MAE from sklearn:\n",
    "    mae_sklr = mean_absolute_error(X@theta.T, y)\n",
    "    assert(math.isclose(mae, mae_sklr))\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7.2\n",
    "Implement the problem from Question 7.1 (Use the `GLPK` solver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to solve LPs from previous question \n",
    "def solve_LP(X, Y, lambda_, k):\n",
    "    d = X.shape[1]\n",
    "    N = X.shape[0]\n",
    "\n",
    "    # auxiliary variables:\n",
    "    Beta = cp.Variable((N, 1))\n",
    "    b = cp.Variable((d, 1))\n",
    "    alpha = cp.Variable((1,1))\n",
    "\n",
    "    # variables to solve:\n",
    "    theta = cp.Variable((1, d))\n",
    "\n",
    "    # linear program:\n",
    "    prob = cp.Problem( cp.Minimize(k * alpha + cp.sum(Beta) + lambda_ * cp.sum(b)), \n",
    "                      [\n",
    "        alpha + Beta >= 1/k * (Y - X @ theta.T),\n",
    "        alpha + Beta >= -1/k * (Y - X @ theta.T),\n",
    "        Beta >= 0,\n",
    "        -b <= theta,\n",
    "        theta <= b\n",
    "    ])\n",
    "\n",
    "    # solve LP:\n",
    "    prob.solve(solver=cp.GLPK)\n",
    "    theta_opt = theta.value\n",
    "    alpha_opt = b.value\n",
    "    \n",
    "    opt_value = prob.value\n",
    "    dual_value = prob.constraints[0].dual_value\n",
    "    return theta_opt,  opt_value, dual_value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters:\n",
    "lambda_ = np.logspace(-5, -1, 50, base = 10)\n",
    "lambda_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "diabetes = load_diabetes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 75% split:\n",
    "X, X_test, Y, Y_test = train_test_split(diabetes['data'], \n",
    "                                        np.expand_dims(diabetes['target'], 1), \n",
    "                                        test_size=0.25, random_state=0)\n",
    "# Add bias column to data:\n",
    "X = np.concatenate((X, np.ones((X.shape[0], 1))), axis=1)\n",
    "X_test = np.concatenate((X_test, np.ones((X_test.shape[0], 1))), axis=1)\n",
    "\n",
    "e_train, e_val, thetas, opt_val = [], [], [], []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation for 50 values of lambda:\n",
    "for l in lambda_:\n",
    "    theta_opt, opt_value, dual_value = solve_LP(X, Y, l, math.floor(0.75 * X.shape[0]))\n",
    "    thetas.append(theta_opt)\n",
    "    opt_val.append(opt_value)\n",
    "    \n",
    "    # evaluate on training set:\n",
    "    e_train.append(get_MAE(theta_opt, X, Y))\n",
    "    # evaluate on validation set:\n",
    "    e_val.append(get_MAE(theta_opt, X_test, Y_test))\n",
    "    \n",
    "# take hyperparameter with smallest validation error:\n",
    "best_lambda = lambda_[np.argmin(e_val)]\n",
    "best_theta = thetas[np.argmin(e_val)]\n",
    "best_value = opt_val[np.argmin(e_val)]\n",
    "\n",
    "print('---Optimal values--')\n",
    "print(f'Optimal lambda: {best_lambda}')\n",
    "print(f'Optimal value: {best_value}')\n",
    "print(f'Optimal theta:\\n {best_theta}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(color.BOLD + 'Training Results' + color.END)\n",
    "print('MAE: {}'.format(get_MAE(best_theta, X, Y)))\n",
    "print('\\n')\n",
    "print(color.BOLD + 'Test Results' + color.END)\n",
    "print('MAE: {}'.format(get_MAE(best_theta, X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
